<p align="center">
  <img src="https://github.com/athul-kurian/vae-latent-space-explorer/blob/main/assets/banner.gif" alt="" style="width:100%; height:auto;"/>
</p>

# VAE Latent Space Explorer

A simple tool to explore the **latent space of a Variational Autoencoder (VAE)** trained on handwritten digit images (e.g., MNIST).  
This project allows you to visualize and generate digit images by sampling or navigating the VAEâ€™s latent space.

## ğŸ¯ Features

- ğŸ§  Decode latent vectors into images using a pretrained VAE decoder
- ğŸ–¼ï¸ Interactive GUI to explore the latent space and view generated digits in real time
- ğŸ“ Jupyter notebook demonstrating latent space sampling and visualization

## ğŸ“ Repository Structure

```
â”œâ”€â”€ assets/                     # Static assets
â”œâ”€â”€ decoder.py                  # VAE decoder implementation
â”œâ”€â”€ gui.py                      # GUI for latent space exploration
â”œâ”€â”€ LatentDigits.ipynb          # Notebook demo
â”œâ”€â”€ decoder_weights.pt          # Pretrained decoder weights
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Getting Started

### ğŸ› ï¸ Requirements

- Python 3.7+
- PyTorch
- tkinter
- matplotlib
- numpy

Install dependencies:

```bash
pip install torch matplotlib numpy
```

> Note: `tkinter` is usually included with Python installations.

### ğŸ§ª Running the Notebook

```bash
jupyter notebook LatentDigits.ipynb
```

This notebook demonstrates:
- Loading the pretrained decoder
- Sampling points in latent space
- Visualizing generated digits

### ğŸ–¥ï¸ Running the GUI

```bash
python gui.py
```

Use the GUI controls to modify latent variables and observe how the generated digit changes.

## ğŸ§  VAE Architecture

This project implements a **convolutional Variational Autoencoder (VAE)** designed for MNIST digits.

### Encoder

- Input: `1 Ã— 28 Ã— 28` grayscale image
- Two strided convolutional layers
- Outputs latent mean (`Î¼`) and log-variance (`logÏƒÂ²`)

**Layers**
- Conv2d(1 â†’ 16, kernel=4, stride=2) + ReLU
- Conv2d(16 â†’ 32, kernel=4, stride=2) + ReLU
- Flatten
- Linear(32Ã—7Ã—7 â†’ latent_dim) â†’ `Î¼`
- Linear(32Ã—7Ã—7 â†’ latent_dim) â†’ `logÏƒÂ²`

### Reparameterization

```
z = Î¼ + exp(0.5 Â· logÏƒÂ²) âŠ™ Îµ,   Îµ ~ N(0, I)
```

### Decoder

- Linear(latent_dim â†’ 32Ã—7Ã—7)
- Reshape â†’ feature maps
- ConvTranspose2d(32 â†’ 16, kernel=4, stride=2) + ReLU
- ConvTranspose2d(16 â†’ 1, kernel=4, stride=2) + Tanh

### Forward Pass

1. Encode image â†’ `Î¼`, `logÏƒÂ²`
2. Sample latent vector `z`
3. Decode `z` â†’ reconstructed image
4. Return reconstruction and latent statistics


## ğŸ“¦ Model Weights

The pretrained decoder weights are stored in:

```
decoder_weights.pt
```

These weights are loaded automatically by the decoder code.

## ğŸ“ Example Usage

```python
from decoder import Decoder
import torch

model = Decoder()
model.load_state_dict(torch.load("decoder_weights.pt"))
model.eval()

z = torch.randn(1, 2)
img = model.decode(z)
```

## ğŸ“Œ Notes

- This is an educational project intended for understanding VAEs and latent spaces
- You can extend this project to other datasets or higher-dimensional latent spaces

## ğŸ“œ License

Specify your license here.
